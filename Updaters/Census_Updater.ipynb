{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **INSTRUCTIONS**\n",
        "\n",
        "Note: please DO NOT change the names of the master files, config files, updaters, or the folders that they are contained in. It will break the notebook.\n",
        "\n",
        "###**WHAT THE NOTEBOOK DOES**\n",
        "\n",
        "1) Retrieve relevant data from the census bureau using the Census API (the API is for the ACS data profiles).\n",
        "\n",
        "2) Insert the retrieved data into the demographics, income, and housing master sheets.\n",
        "\n",
        "### **HOW TO RUN THE NOTEBOOK**\n",
        "To use the notebook, go to \"Runtime\" and click \"Run All\". A popup will appear asking for permission to access your google drive. Give the notebook permissions for everything by connecting it to your google account.\n",
        "\n",
        "The notebook will only edit files contained in the folder titled \"SVED Economic Profile Auto-Updaters\".\n",
        "\n",
        "Notebook execution typically takes less than 45 seconds. If execution takes more than 5 minutes, or if you encounter an error, please go to \"Runtime\" and select \"Run All\" again, and the problem should resolve itself.\n",
        "\n",
        "### **HOW TO ACCESS MASTERS**##\n",
        "\n",
        "The masters can be accessed from the \"Masters\" folder. Please do not remove them. If you want them on your local machine, please download them.\n",
        "\n",
        "### **HOW TO SET CONFIGURATION FILE**\n",
        "\n",
        "The set the config file, edit \"Census_updater_config.txt\". The config file contains instructions for how to edit it. The most important thing to know is that you should ONLY change the values of the variables, and nothing else in the file (including its name).\n",
        "\n",
        "In general, the only variable you will have to change is the year"
      ],
      "metadata": {
        "id": "NaQRucCQBMzS"
      },
      "id": "NaQRucCQBMzS"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5917d899-5df5-4b27-b27a-24002ae9a8bd",
      "metadata": {
        "id": "5917d899-5df5-4b27-b27a-24002ae9a8bd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import csv\n",
        "import json\n",
        "from urllib.request import Request, urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import ast\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c5ee928-3e87-4dca-a17c-d4b58235537f",
      "metadata": {
        "id": "7c5ee928-3e87-4dca-a17c-d4b58235537f"
      },
      "source": [
        "# 1. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "eaiSSA55RFdK",
      "metadata": {
        "id": "eaiSSA55RFdK"
      },
      "outputs": [],
      "source": [
        "## 1.1 Give Google Colab Access to your drive. This is important. Give it access to everything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "Yh2nj3qfQmIo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh2nj3qfQmIo",
        "outputId": "a0be6a8e-455e-47dc-f368-d9d819154e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "qkcZv2eVQwKm",
      "metadata": {
        "id": "qkcZv2eVQwKm"
      },
      "outputs": [],
      "source": [
        "## 1.2 Get Config from File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "7615db7b-703f-4faa-a5ae-4a093434c5f6",
      "metadata": {
        "id": "7615db7b-703f-4faa-a5ae-4a093434c5f6"
      },
      "outputs": [],
      "source": [
        "def get_parameters(config : str, parameter_names: list, parameter_types: list):\n",
        "    \"\"\"\n",
        "    config -- the directory of the config file\n",
        "    parameters_names -- the names of the parameters to fetch from the config file\n",
        "    parameter_types -- the types of the parameters in parameters_names. Must match the length of parameter_names\n",
        "\n",
        "    returns -- parameters, a list-like of tuples: (parameter value, parameter type)\n",
        "    \"\"\"\n",
        "    parameters = {}\n",
        "    i = config.find(\"%%%%%%%\")\n",
        "    config = config[i:-1]\n",
        "    j = 0\n",
        "    for param in parameter_names:\n",
        "        value = \"\"\n",
        "        i = config.find(param) + len(param) + 1\n",
        "        while (config[i] != \"\\n\"):\n",
        "            if(config[i] != \" \" and config[i] != \":\"):\n",
        "                value += config[i]\n",
        "            i += 1\n",
        "        parameters[param] = [value, parameter_types[j]]\n",
        "        j += 1\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ad396f29-d80a-4ce9-a0f9-a5558c8139f4",
      "metadata": {
        "id": "ad396f29-d80a-4ce9-a0f9-a5558c8139f4"
      },
      "outputs": [],
      "source": [
        "def validate_parameters(parameters):\n",
        "    \"\"\"\n",
        "    parameters -- a list-like of tuples: (parameter value, parameter type).\n",
        "\n",
        "    returns -- 0 if parameters are valid. -1 otherwise.\n",
        "    \"\"\"\n",
        "    for param in parameters:\n",
        "        if(parameters[param][1] == \"int\"):\n",
        "            if(not parameters[param][0].isdigit()):\n",
        "                raise Exception(\"non-digit int detected: \" + parameters[param][0])\n",
        "                return -1\n",
        "            if(param == \"year\" and (int(parameters[param][0]) < 2019 or int(parameters[param][0]) >= int(datetime.now().year))):\n",
        "                raise Exception(\"invalid year selected: please choose a year in [2019, current)!\")\n",
        "                return -1\n",
        "        if(parameters[param][1] == \"bool\"):\n",
        "            if(not parameters[param][0] in [\"True\", \"False\"]):\n",
        "                raise Exception(\"invalid boolean detected: \" + parameters[param][0])\n",
        "                return -1\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "5f02d719-05cb-4951-8e1c-042491eecb34",
      "metadata": {
        "id": "5f02d719-05cb-4951-8e1c-042491eecb34"
      },
      "outputs": [],
      "source": [
        "def convert_parameters(parameters):\n",
        "    \"\"\"\n",
        "    parameters -- a list-like of tuples: (parameter value, parameter type).\n",
        "\n",
        "    returns -- parameters, the same list-like as the input, except for each tuple (parameter value, parameter type), parameter value is an object of the type specified by paramter value (leaves it as a string if left unspecified).\n",
        "    \"\"\"\n",
        "    for param in parameters:\n",
        "        if(parameters[param][1] == \"bool\"):\n",
        "            if(parameters[param][0] == \"True\"):\n",
        "                parameters[param][0] = True\n",
        "            if(parameters[param][0] == \"False\"):\n",
        "                parameters[param][0] = False\n",
        "        if(parameters[param][1] == \"int\"):\n",
        "            parameters[param][0] = int(parameters[param][0])\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "3cc55ef6-e501-446c-a333-5e6f8cfa38c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cc55ef6-e501-446c-a333-5e6f8cfa38c5",
        "outputId": "17d35035-4975-4b92-dfd7-c7bdaef2ab0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# get parameters and make sure they are valid\n",
        "config = open('/content/drive/MyDrive/SVED Economic Profile Auto-Updaters/Updaters/Census_updater_config.txt', \"r\")\n",
        "config = config.read()\n",
        "parameters = get_parameters(config, [\"key\", \"year\", \"include_DP05\", \"include_DP04\", \"include_DP03\"], [\"str\", \"str\", \"bool\", \"bool\", \"bool\"])\n",
        "validate_parameters(parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "EtsWvwYVVJId",
      "metadata": {
        "id": "EtsWvwYVVJId"
      },
      "outputs": [],
      "source": [
        "# assign parameters to our varaibles\n",
        "parameters = convert_parameters(parameters)\n",
        "KEY = str(parameters[\"key\"][0])\n",
        "YEAR = str(parameters[\"year\"][0])\n",
        "include_DP05 = parameters[\"include_DP05\"][0]\n",
        "include_DP04 = parameters[\"include_DP04\"][0]\n",
        "include_DP03 = parameters[\"include_DP03\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6914e1e4-a2da-49c6-9b6c-b576cad5e87e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6914e1e4-a2da-49c6-9b6c-b576cad5e87e",
        "outputId": "f353d3a1-07f2-4e09-c666-a5a598345bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KEY:  356157f0675bf8ad17969b216569bd70244f5d63\n",
            "YEAR:  2017\n"
          ]
        }
      ],
      "source": [
        "print(\"KEY: \", KEY)\n",
        "print(\"YEAR: \", YEAR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9372105-b8ee-4ebc-822a-089251ec3b0f",
      "metadata": {
        "id": "c9372105-b8ee-4ebc-822a-089251ec3b0f"
      },
      "source": [
        "# 2. Functions for Querying"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84d891b8-da87-4c05-960f-5ea3ceaa0761",
      "metadata": {
        "id": "84d891b8-da87-4c05-960f-5ea3ceaa0761"
      },
      "source": [
        "## 2.1 Data Getters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "badb9189-a15f-45a6-8b9d-15e781566700",
      "metadata": {
        "id": "badb9189-a15f-45a6-8b9d-15e781566700"
      },
      "outputs": [],
      "source": [
        "def all_number_entries(df : pd.DataFrame()) -> bool:\n",
        "    numeric_checker = pd.DataFrame()\n",
        "    for i in range(0, len(locations)):\n",
        "        for col in df.columns:\n",
        "            numeric_checker.loc[locations[i],col] = int(isnumber(df.loc[locations[i],col]))\n",
        "    if ((len(df.columns) * len(df.index)) > numeric_checker.sum().sum()):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def flatten_string(s):\n",
        "    container = []\n",
        "    temp = \"\"\n",
        "    for char in s:\n",
        "        if(char != \"[\" and char != \"]\"):\n",
        "            if(char == \",\"):\n",
        "                container += [temp]\n",
        "                temp = \"\"\n",
        "            else:\n",
        "                 if(char != '\"'):\n",
        "                        temp += char\n",
        "    return container\n",
        "\n",
        "def isnumber(s : str) -> bool:\n",
        "    has_decimal = False\n",
        "    for char in s:\n",
        "        if(not char.isdigit()):\n",
        "            if (char != \".\"):\n",
        "                return False\n",
        "            else:\n",
        "                if(has_decimal):\n",
        "                    return False\n",
        "                has_decimal = True\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "d0242cb7-93e3-4780-a799-d6ee36bc2e57",
      "metadata": {
        "id": "d0242cb7-93e3-4780-a799-d6ee36bc2e57"
      },
      "outputs": [],
      "source": [
        "def get_census_table(url : str, col_names : list, index_cols : list = [0], index_names : list = [None]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "        url: string containing the url to be parsed for data.\n",
        "        col_names: list-like of the names that will be used to rename the dataframe.\n",
        "                    must match the dimensions of the data retrieved.\n",
        "        index_cols: a list-like of integers containing the indices of the columns which will become the index.\n",
        "                    constructs a multi-index with the first integer in index_cols being the highest level of\n",
        "                    the index.\n",
        "        index_names: a list-like containing the labels for the (multi-leveled) index\n",
        "        returns: a pandas dataframe containing the data from url.\n",
        "    \"\"\"\n",
        "    # get the data\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "    df = pd.DataFrame(ast.literal_eval(str(soup)))\n",
        "\n",
        "    # set the new index\n",
        "    new_index = pd.MultiIndex.from_frame(df.iloc[:,index_cols])\n",
        "    df = df.set_index(new_index)\n",
        "\n",
        "    # drop columns we are using as the index\n",
        "    drop_cols = []\n",
        "    for col_index in index_cols:\n",
        "        drop_cols += [df.columns[col_index]]\n",
        "    df = df.drop(columns = drop_cols)\n",
        "\n",
        "    # change the column names as desired\n",
        "    if(len(col_names) == len(df.columns)):\n",
        "        df.columns = col_names\n",
        "\n",
        "    # get rid of index name\n",
        "    df.index.names = index_names\n",
        "\n",
        "    # get rid of the row that contained the column names\n",
        "    df = df.drop(index = df.iloc[0].name, errors = \"ignore\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "d9663497-b235-44fa-a4a5-62c9e003e0cf",
      "metadata": {
        "id": "d9663497-b235-44fa-a4a5-62c9e003e0cf"
      },
      "outputs": [],
      "source": [
        "def get_custom_tables(SUMMARY : pd.DataFrame(), category_names : list, category_target_names : list, category_target_codes : list) -> list:\n",
        "    tables = []\n",
        "    for i in range(0, len(category_names)):\n",
        "        tables += [pd.DataFrame()]\n",
        "    for i in range(0, len(category_names)):\n",
        "        for j in range(0, len(locations)):\n",
        "            for k in range(0, len(category_target_names[i])):\n",
        "                tables[i].loc[locations[j], category_target_names[i][k]] = SUMMARY.loc[locations[j],category_target_codes[i][k]]\n",
        "\n",
        "        # look for non-numbers (incorrect values which make it impossible to enter the data)\n",
        "        if(not all_number_entries(tables[i])):\n",
        "                print(\"ERROR: non-numeric values detected in \" + category_names[i])\n",
        "\n",
        "        # turn to numbers\n",
        "        for col in tables[i].columns:\n",
        "            tables[i][col] = tables[i][col].apply(float)\n",
        "    return tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "a3b7a5ab-821b-49fe-baaa-84d3e30597bb",
      "metadata": {
        "id": "a3b7a5ab-821b-49fe-baaa-84d3e30597bb"
      },
      "outputs": [],
      "source": [
        "def make_summary_table(YEAR : str, locations : list, location_codes : list, group : str) -> pd.DataFrame():\n",
        "    print(\"\\nQUERYING: \" + group + \", YEAR: \" + YEAR)\n",
        "    location_data = []\n",
        "    for i in range(0, len(locations)):\n",
        "        # get the data for the location\n",
        "        if(locations[i] == \"BLAINE\"):\n",
        "            url = \"https://api.census.gov/data/\" + YEAR + \"/acs/acs5/profile?get=\" + \"group(\" + group + \")&for=county:\" + str(location_codes[i].iloc[1]) + \"&in=state:\" + str(location_codes[i].iloc[0]) + \"&key=\" + KEY\n",
        "        else:\n",
        "            url = \"https://api.census.gov/data/\" + YEAR + \"/acs/acs5/profile?get=\" + \"group(\" + group + \")&for=place:\" + str(location_codes[i].iloc[1]) + \"&in=state:\" + str(location_codes[i].iloc[0]) + \"&key=\" + KEY\n",
        "        # get the raw html and process it\n",
        "        page = requests.get(url)\n",
        "\n",
        "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "        soup = str(soup).replace(\"null\", '\"null\"') # necessary for ast.literal_eval to work (treats null as a string, \"null\", instead of a datatype)\n",
        "        soup = soup.replace(\"\\n\", \"\") # get rid of an extra endline character in the middle of the soup (not necessary)\n",
        "        df = pd.DataFrame(ast.literal_eval(soup)) # turn the html into a dataframe\n",
        "        df.columns = df.loc[0,:] # rename the dataframe to be the ACS variable names\n",
        "        df = df.drop(index = 0)\n",
        "        location_data += [df]\n",
        "        print(\"\\tPROCESSED: \" + locations[i])\n",
        "\n",
        "    # make a huge sumamry dataframe\n",
        "    SUMMARY = pd.DataFrame(columns = location_data[0].columns)\n",
        "    for ldf in location_data:\n",
        "        SUMMARY = pd.concat([SUMMARY, ldf], axis = 0)\n",
        "    SUMMARY.index = locations\n",
        "\n",
        "    return SUMMARY"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86c6a33e-6c3a-48ca-8d79-0a1b6efb1388",
      "metadata": {
        "id": "86c6a33e-6c3a-48ca-8d79-0a1b6efb1388"
      },
      "source": [
        "## 2.2 Census Code Getters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "fb976933-731b-4ef2-b716-08ca77b39a3f",
      "metadata": {
        "id": "fb976933-731b-4ef2-b716-08ca77b39a3f"
      },
      "outputs": [],
      "source": [
        "def filter_keywords_and(kws, s, keep_matches):\n",
        "    sl = s.lower()\n",
        "    for kw in kws:\n",
        "        if kw.lower() not in sl:\n",
        "            return not keep_matches\n",
        "    return keep_matches\n",
        "\n",
        "def filter_keywords_or(kws, s, keep_matches):\n",
        "    sl = s.lower()\n",
        "    for kw in kws:\n",
        "        if kw.lower() in sl:\n",
        "            return keep_matches\n",
        "    return not keep_matches\n",
        "\n",
        "def get_race_codes(year):\n",
        "    # get variables list for the desired year and reformat\n",
        "    url = \"https://api.census.gov/data/\" + str(year) + \"/acs/acs5/profile/variables\"\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "    soup = str(soup).replace(\"null\", '\"null\"') # necessary for ast.literal_eval to work (treats null as a string, \"null\", instead of a datatype)\n",
        "    soup = soup.replace(\"\\n\", \"\") # get rid of an extra endline character in the middle of the soup (not necessary)\n",
        "    df = pd.DataFrame(ast.literal_eval(soup))\n",
        "    df = df.rename(columns = {0:\"name\", 1:\"label\", 2:\"concept\"})\n",
        "    df.drop(index = 0)\n",
        "    df = df.reset_index().drop(columns = [\"index\"])\n",
        "\n",
        "    # filter to DP05\n",
        "    df[\"mask\"] = df[\"name\"].apply(lambda s: \"DP05\" in s)\n",
        "    df = df.query(\"mask == True\").drop(columns = [\"mask\"])\n",
        "\n",
        "    # get codes\n",
        "    labels = {}\n",
        "    # white\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"white\", \"alone\", \"not\"], s, True) and filter_keywords_and([\"percent\"], s, False) and filter_keywords_or([\"hispanic\", \"latino\"], s, True))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"White\"] = label_df.iloc[0,0]\n",
        "    # latino\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"any\"], s, True) and filter_keywords_and([\"percent\"], s, False) and filter_keywords_or([\"hispanic\", \"latino\"], s, True))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    label_df = label_df.sort_values(by = [\"name\"]) # choose the first one (which will be the \"all\" category\")\n",
        "    labels[\"Latino\"] = label_df.iloc[0,0]\n",
        "    # black\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"alone\", \"not\"], s, True) and filter_keywords_or([\"black\", \"african american\"], s, True) and filter_keywords_and([\"percent\"], s, False) and filter_keywords_or([\"hispanic\", \"latino\"], s, True))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"Black\"] = label_df.iloc[0,0]\n",
        "    # american indian\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"alone\", \"not\"], s, True) and (filter_keywords_and([\"indian\"], s, True) or filter_keywords_and([\"native\", \"american\"],s, True)) and filter_keywords_and([\"percent\"], s, False) and filter_keywords_or([\"hispanic\", \"latino\"], s, True))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"American Indian\"] = label_df.iloc[0,0]\n",
        "    # asian\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"asian\", \"alone\", \"not\"], s, True) and filter_keywords_and([\"percent\"], s, False) and filter_keywords_or([\"hispanic\", \"latino\"], s, True))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"Asian\"] = label_df.iloc[0,0]\n",
        "    # hawaiian/pi\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"hawaiian\", \"alone\", \"not\"], s, True) and filter_keywords_and([\"percent\"], s, False) and filter_keywords_or([\"hispanic\", \"latino\"], s, True))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"Hawaiian/PI\"] = label_df.iloc[0,0]\n",
        "    # other\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"other\", \"alone\", \"not\"], s, True) and filter_keywords_or([\"percent\", \"hawaiian\", \"pacific\"], s, False) and filter_keywords_or([\"hispanic\", \"latino\"], s, True))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"Other\"] = label_df.iloc[0,0]\n",
        "    # two or more\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"two\", \"not\"], s, True) and filter_keywords_or([\"percent\", \"other\"], s, False) and filter_keywords_or([\"hispanic\", \"latino\"], s, True))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"Two or More\"] = label_df.iloc[0,0]\n",
        "\n",
        "    return labels\n",
        "\n",
        "def get_age_codes(year):\n",
        "    # get variables list for the desired year and reformat\n",
        "    url = \"https://api.census.gov/data/\" + str(year) + \"/acs/acs5/profile/variables\"\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "    soup = str(soup).replace(\"null\", '\"null\"') # necessary for ast.literal_eval to work (treats null as a string, \"null\", instead of a datatype)\n",
        "    soup = soup.replace(\"\\n\", \"\") # get rid of an extra endline character in the middle of the soup (not necessary)\n",
        "    df = pd.DataFrame(ast.literal_eval(soup))\n",
        "    df = df.rename(columns = {0:\"name\", 1:\"label\", 2:\"concept\"})\n",
        "    df.drop(index = 0)\n",
        "    df = df.reset_index().drop(columns = [\"index\"])\n",
        "\n",
        "    # filter to DP05\n",
        "    df[\"mask\"] = df[\"name\"].apply(lambda s: \"DP05\" in s)\n",
        "    df = df.query(\"mask == True\").drop(columns = [\"mask\"])\n",
        "\n",
        "    # get codes\n",
        "    labels = {}\n",
        "    # <5 yrs\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\" 5 years\"], s, True) and filter_keywords_and([\"percent\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"<5 yrs\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 5 - 9 yrs\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\" 9 years\"], s, True) and filter_keywords_and([\"percent\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"5-9 yrs\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 10 - 14 yrs\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\" 14 years\"], s, True) and filter_keywords_and([\"percent\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"10-14 yrs\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 15 - 19 yrs\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\" 19 years\"], s, True) and filter_keywords_and([\"percent\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"15-19 yrs\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 20 - 24 yrs\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\" 24 years\"], s, True) and filter_keywords_and([\"percent\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"20-24 yrs\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 25 - 34 yrs\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\" 34 years\"], s, True) and filter_keywords_and([\"percent\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"25-34 yrs\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 35 - 44 yrs\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\" 44 years\"], s, True) and filter_keywords_and([\"percent\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"35-44 yrs\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 45 - 54 yrs\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\" 54 years\"], s, True) and filter_keywords_and([\"percent\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"45-54 yrs\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 55 - 59 yrs\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\" 59 years\"], s, True) and filter_keywords_and([\"percent\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"55-59 yrs\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 60 - 64 yrs\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\" 64 years\"], s, True) and filter_keywords_and([\"percent\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"60-64 yrs\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 65 - 74 yrs\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\" 74 years\"], s, True) and filter_keywords_and([\"percent\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"65-74 yrs\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 75 - 84 yrs\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\" 84 years\"], s, True) and filter_keywords_and([\"percent\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"75-84 yrs\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # >85 yrs\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"85 years\"], s, True) and filter_keywords_and([\"percent\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\">85 yrs\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # Median\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"median\", \"age\"], s, True) and filter_keywords_and([\"percent\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"Median Age\"] = label_df.iloc[0,0]\n",
        "\n",
        "    return labels\n",
        "\n",
        "def get_sex_codes(year):\n",
        "    # get variables list for the desired year and reformat\n",
        "    url = \"https://api.census.gov/data/\" + str(year) + \"/acs/acs5/profile/variables\"\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "    soup = str(soup).replace(\"null\", '\"null\"') # necessary for ast.literal_eval to work (treats null as a string, \"null\", instead of a datatype)\n",
        "    soup = soup.replace(\"\\n\", \"\") # get rid of an extra endline character in the middle of the soup (not necessary)\n",
        "    df = pd.DataFrame(ast.literal_eval(soup))\n",
        "    df = df.rename(columns = {0:\"name\", 1:\"label\", 2:\"concept\"})\n",
        "    df.drop(index = 0)\n",
        "    df = df.reset_index().drop(columns = [\"index\"])\n",
        "\n",
        "    # filter to DP05\n",
        "    df[\"mask\"] = df[\"name\"].apply(lambda s: \"DP05\" in s)\n",
        "    df = df.query(\"mask == True\").drop(columns = [\"mask\"])\n",
        "\n",
        "    # get labels\n",
        "    labels = {}\n",
        "\n",
        "    # total\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"sex\", \"age\", \"total\", \"population\"], s, True) and filter_keywords_or([\"percent\", \"male\", \"female\", \"other\", \"ratio\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    label_df = label_df.sort_values(by = \"name\")\n",
        "    labels[\"Total Population\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # total male\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"sex\", \"age\", \"male\"], s, True) and filter_keywords_or([\"percent\", \"female\", \"other\", \"ratio\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    label_df = label_df.sort_values(by = \"name\")\n",
        "    labels[\"Total Male\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # total female\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"sex\", \"age\", \"female\"], s, True) and filter_keywords_or([\"percent\", \"other\", \"ratio\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    label_df = label_df.sort_values(by = \"name\")\n",
        "    labels[\"Total Female\"] = label_df.iloc[0,0]\n",
        "\n",
        "    return labels\n",
        "\n",
        "def get_housing_codes(year):\n",
        "    # get variables list for the desired year and reformat\n",
        "    url = \"https://api.census.gov/data/\" + str(year) + \"/acs/acs5/profile/variables\"\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "    soup = str(soup).replace(\"null\", '\"null\"') # necessary for ast.literal_eval to work (treats null as a string, \"null\", instead of a datatype)\n",
        "    soup = soup.replace(\"\\n\", \"\") # get rid of an extra endline character in the middle of the soup (not necessary)\n",
        "    df = pd.DataFrame(ast.literal_eval(soup))\n",
        "    df = df.rename(columns = {0:\"name\", 1:\"label\", 2:\"concept\"})\n",
        "    df.drop(index = 0)\n",
        "    df = df.reset_index().drop(columns = [\"index\"])\n",
        "\n",
        "    # filter to DP04\n",
        "    df[\"mask\"] = df[\"name\"].apply(lambda s: \"DP04\" in s)\n",
        "    df = df.query(\"mask == True\").drop(columns = [\"mask\"])\n",
        "\n",
        "    # get labels\n",
        "    labels = {}\n",
        "\n",
        "    # owner occupied\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"owner\", \"occupied\"], s, True) and filter_keywords_or([\"percent\", \"household\", \"size\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"Owner Occupied\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # renter occupied\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"renter\", \"occupied\"], s, True) and filter_keywords_or([\"percent\", \"household\", \"size\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"Renter Occupied\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # vacant/seasonal occupied\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"vacant\", \"housing\"], s, True) and filter_keywords_or([\"percent\", \"household\", \"size\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"Season/Vac\"] = label_df.iloc[0,0]\n",
        "\n",
        "    return labels\n",
        "\n",
        "def get_income_codes(year):\n",
        "       # get variables list for the desired year and reformat\n",
        "    url = \"https://api.census.gov/data/\" + str(year) + \"/acs/acs5/profile/variables\"\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "    soup = str(soup).replace(\"null\", '\"null\"') # necessary for ast.literal_eval to work (treats null as a string, \"null\", instead of a datatype)\n",
        "    soup = soup.replace(\"\\n\", \"\") # get rid of an extra endline character in the middle of the soup (not necessary)\n",
        "    df = pd.DataFrame(ast.literal_eval(soup))\n",
        "    df = df.rename(columns = {0:\"name\", 1:\"label\", 2:\"concept\"})\n",
        "    df.drop(index = 0)\n",
        "    df = df.reset_index().drop(columns = [\"index\"])\n",
        "\n",
        "    # filter to DP03\n",
        "    df[\"mask\"] = df[\"name\"].apply(lambda s: \"DP03\" in s)\n",
        "    df = df.query(\"mask == True\").drop(columns = [\"mask\"])\n",
        "\n",
        "    # get labels\n",
        "    labels = {}\n",
        "\n",
        "    # <10k\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"than $10,000\", \"household\"], s, True) and filter_keywords_or([\"benefits\", \"income\"], s, True) and filter_keywords_or([\"percent\", \"family\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"<10k\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 10k - 14k\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"to $14,999\", \"household\"], s, True) and filter_keywords_or([\"benefits\", \"income\"], s, True) and filter_keywords_or([\"percent\", \"family\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"10k-14k\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 15k - 25k\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"to $24,999\", \"household\"], s, True) and filter_keywords_or([\"benefits\", \"income\"], s, True) and filter_keywords_or([\"percent\", \"family\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"15k-25k\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 25k - 35k\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"to $34,999\", \"household\"], s, True) and filter_keywords_or([\"benefits\", \"income\"], s, True) and filter_keywords_or([\"percent\", \"family\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"25k-35k\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 35k - 50k\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"to $49,999\", \"household\"], s, True) and filter_keywords_or([\"benefits\", \"income\"], s, True) and filter_keywords_or([\"percent\", \"family\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"35k-50k\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 50k - 75k\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"to $74,999\", \"household\"], s, True) and filter_keywords_or([\"benefits\", \"income\"], s, True) and filter_keywords_or([\"percent\", \"family\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"50k-75k\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 75k - 100k\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"to $99,999\", \"household\"], s, True) and filter_keywords_or([\"benefits\", \"income\"], s, True) and filter_keywords_or([\"percent\", \"family\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"75k-100k\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 100k - 150k\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"to $149,999\", \"household\"], s, True) and filter_keywords_or([\"benefits\", \"income\"], s, True) and filter_keywords_or([\"percent\", \"family\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"100k-150k\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # 150k - 200k\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"to $199,999\", \"household\"], s, True) and filter_keywords_or([\"benefits\", \"income\"], s, True) and filter_keywords_or([\"percent\", \"family\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"150k-200k\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # >200k\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"$200,000\", \"more\"], s, True) and filter_keywords_or([\"benefits\", \"income\"], s, True) and filter_keywords_or([\"percent\", \"family\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\">=200k\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # Households\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"total\", \"household\"], s, True) and filter_keywords_or([\"benefits\", \"income\"], s, True) and filter_keywords_or([\"percent\", \"family\", \"$\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    label_df = label_df.sort_values(by = \"name\")\n",
        "    labels[\"Total Households\"] = label_df.iloc[0,0]\n",
        "\n",
        "    # Median Income\n",
        "    df[\"mask\"] = df[\"label\"].apply(lambda s: filter_keywords_and([\"median\", \"household\"], s, True) and filter_keywords_or([\"benefits\", \"income\"], s, True) and filter_keywords_or([\"percent\", \"family\", \"$\"], s, False))\n",
        "    label_df = df.query(\"mask == True\").reset_index().drop(columns = [\"index\"])\n",
        "    labels[\"Median Income\"] = label_df.iloc[0,0]\n",
        "\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b149fbc-1768-4f05-b7c1-d0b81accba92",
      "metadata": {
        "id": "2b149fbc-1768-4f05-b7c1-d0b81accba92"
      },
      "source": [
        "# 3. Functions for Exporting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6a5fa19-7dff-4627-82a5-0beffd32be00",
      "metadata": {
        "id": "c6a5fa19-7dff-4627-82a5-0beffd32be00"
      },
      "source": [
        "# 4. Location Codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "8e203e7a-73fa-4d59-b5e1-8ecbcb6fb3b4",
      "metadata": {
        "id": "8e203e7a-73fa-4d59-b5e1-8ecbcb6fb3b4"
      },
      "outputs": [],
      "source": [
        "temp = YEAR\n",
        "YEAR = \"2022\" # can be any recent year, since we are using area codes that don't change year-to-year\n",
        "\n",
        "# url's for the census website containing area codes\n",
        "CITY_NAMES_URL = \"https://api.census.gov/data/\" + YEAR + \"/acs/acs5/profile?get=NAME&for=place:*&key=\" + KEY\n",
        "COUNTY_NAMES_URL = \"https://api.census.gov/data/\" + YEAR + \"/acs/acs5/profile?get=NAME&for=county:*&in=state:*&key=\" + KEY\n",
        "\n",
        "# get city names table\n",
        "city_codes = get_census_table(url = CITY_NAMES_URL, col_names = [\"state_code\", \"city_code\"], index_cols = [0], index_names = [\"city_name\"])\n",
        "# get county names table\n",
        "county_codes = get_census_table(url = COUNTY_NAMES_URL, col_names = [\"state_code\", \"county_code\"], index_cols = [0], index_names = [\"county_name\"])\n",
        "\n",
        "# get codes for each location\n",
        "HAILEY_CODE = city_codes.loc[\"Hailey city, Idaho\"]\n",
        "KETCHUM_CODE = city_codes.loc[\"Ketchum city, Idaho\"]\n",
        "CAREY_CODE = city_codes.loc[\"Carey city, Idaho\"]\n",
        "BELLEVUE_CODE = city_codes.loc[\"Bellevue city, Idaho\"]\n",
        "SV_CODE = city_codes.loc[\"Sun Valley city, Idaho\"]\n",
        "BLAINE_CODE = county_codes.loc[\"Blaine County, Idaho\"]\n",
        "# reset the year back\n",
        "YEAR = temp"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "091a8b8f-15e3-47f4-91cd-c701bd34ae44",
      "metadata": {
        "id": "091a8b8f-15e3-47f4-91cd-c701bd34ae44"
      },
      "source": [
        "# 5. Querying Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "054447c1-851d-4e87-ba74-1486fbdbdd61",
      "metadata": {
        "id": "054447c1-851d-4e87-ba74-1486fbdbdd61"
      },
      "source": [
        "## 5.1. Census Profiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "1e3d0bf7-e59e-4ac0-be1f-8ce9142d4378",
      "metadata": {
        "id": "1e3d0bf7-e59e-4ac0-be1f-8ce9142d4378",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a184dd-ea20-4c30-a2ec-5d1f3b93712d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "QUERYING: DP05, YEAR: 2017\n",
            "\tPROCESSED: HAILEY\n",
            "\tPROCESSED: KETCHUM\n",
            "\tPROCESSED: BELLEVUE\n",
            "\tPROCESSED: CAREY\n",
            "\tPROCESSED: BLAINE\n",
            "\tPROCESSED: SV\n",
            "\n",
            "QUERYING: DP04, YEAR: 2017\n",
            "\tPROCESSED: HAILEY\n",
            "\tPROCESSED: KETCHUM\n",
            "\tPROCESSED: BELLEVUE\n",
            "\tPROCESSED: CAREY\n",
            "\tPROCESSED: BLAINE\n",
            "\tPROCESSED: SV\n",
            "\n",
            "QUERYING: DP03, YEAR: 2017\n",
            "\tPROCESSED: HAILEY\n",
            "\tPROCESSED: KETCHUM\n",
            "\tPROCESSED: BELLEVUE\n",
            "\tPROCESSED: CAREY\n",
            "\tPROCESSED: BLAINE\n",
            "\tPROCESSED: SV\n"
          ]
        }
      ],
      "source": [
        "groups = []\n",
        "if(include_DP05):\n",
        "    groups += [\"DP05\"]\n",
        "if(include_DP04):\n",
        "    groups += [\"DP04\"]\n",
        "if(include_DP03):\n",
        "    groups += [\"DP03\"]\n",
        "\n",
        "census_tables = []\n",
        "YEAR = YEAR\n",
        "locations = [\"HAILEY\", \"KETCHUM\", \"BELLEVUE\", \"CAREY\", \"BLAINE\", \"SV\"]\n",
        "location_codes= [HAILEY_CODE, KETCHUM_CODE, BELLEVUE_CODE, CAREY_CODE, BLAINE_CODE, SV_CODE]\n",
        "for i in range(0, len(groups)):\n",
        "    census_tables += [make_summary_table(YEAR, locations, location_codes, groups[i])]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ecc4a5a-ad4a-4d1e-87e7-b354c122dca2",
      "metadata": {
        "id": "0ecc4a5a-ad4a-4d1e-87e7-b354c122dca2"
      },
      "source": [
        "## 5.2. DP05"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "341d974a-a299-4040-8e71-1692d58b0afb",
      "metadata": {
        "id": "341d974a-a299-4040-8e71-1692d58b0afb"
      },
      "source": [
        "### 5.2.1. Get Data for Demographics Master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "f57683c7-a13f-467d-a2b6-5315b800d21b",
      "metadata": {
        "id": "f57683c7-a13f-467d-a2b6-5315b800d21b"
      },
      "outputs": [],
      "source": [
        "ct_index = 0\n",
        "include_DP05 = True\n",
        "if(include_DP05):\n",
        "    category_names = [\"SEX\", \"AGE\", \"RACE\"]\n",
        "    category_target_names = [\n",
        "        [\"Total Population\",\"Total Male\", \"Total Female\"],\n",
        "        [\"<5 yrs\", \"5-9 yrs\", \"10-14 yrs\", \"15-19 yrs\", \"20-24 yrs\", \"25-34 yrs\", \"35-44 yrs\", \"45-54 yrs\", \"55-59 yrs\", \"60-64 yrs\", \"65-74 yrs\", \"75-84 yrs\", \">85 yrs\", \"Median Age\"],\n",
        "        [\"White\", \"Latino\", \"Black\", \"American Indian\", \"Asian\", \"Hawaiian/PI\", \"Other\", \"Two or More\"]\n",
        "    ]\n",
        "    category_target_codes_sex_dict = get_sex_codes(YEAR)\n",
        "    category_target_codes_age_dict = get_age_codes(YEAR)\n",
        "    category_target_codes_race_dict = get_race_codes(YEAR)\n",
        "\n",
        "    category_target_codes = [[category_target_codes_sex_dict[label] for label in category_target_names[0]],\n",
        "                             [category_target_codes_age_dict[label] for label in category_target_names[1]],\n",
        "                             [category_target_codes_race_dict[label] for label in category_target_names[2]]\n",
        "                            ]\n",
        "    DP05_tables = get_custom_tables(census_tables[ct_index], category_names, category_target_names, category_target_codes)\n",
        "    ct_index += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d044495-b6c8-476a-8320-a04307168c61",
      "metadata": {
        "id": "1d044495-b6c8-476a-8320-a04307168c61"
      },
      "source": [
        "### 5.2.2. Reformat Data for Master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "51f69f0b-65bf-4004-9306-20074fe5df70",
      "metadata": {
        "id": "51f69f0b-65bf-4004-9306-20074fe5df70"
      },
      "outputs": [],
      "source": [
        "if(include_DP05):\n",
        "    # sex: none needed!\n",
        "    i = 0\n",
        "\n",
        "    # age\n",
        "    i = 1\n",
        "    # group by master sheet categories\n",
        "    DP05_tables[i].loc[:,\"<20 yrs\"] = DP05_tables[i].loc[:, [\"<5 yrs\", \"5-9 yrs\", \"10-14 yrs\", \"15-19 yrs\"]].sum(axis = 1)\n",
        "    DP05_tables[i].loc[:,\"20-34 yrs\"] = DP05_tables[i].loc[:, [\"20-24 yrs\", \"25-34 yrs\"]].sum(axis = 1)\n",
        "    DP05_tables[i].loc[:,\"35-54 yrs\"] = DP05_tables[i].loc[:, [\"35-44 yrs\", \"45-54 yrs\"]].sum(axis = 1)\n",
        "    DP05_tables[i].loc[:,\"55-64 yrs\"] = DP05_tables[i].loc[:, [\"55-59 yrs\", \"60-64 yrs\"]].sum(axis = 1)\n",
        "    DP05_tables[i].loc[:,\">64 yrs\"] = DP05_tables[i].loc[:, [\"65-74 yrs\", \"75-84 yrs\", \">85 yrs\"]].sum(axis = 1)\n",
        "    temp = DP05_tables[i].loc[:,[\"<20 yrs\", \"20-34 yrs\", \"35-54 yrs\", \"55-64 yrs\", \">64 yrs\"]].copy(deep = True)\n",
        "    temp[\"Total\"] = temp.loc[:,:].sum(axis = 1)\n",
        "    temp[\"Median Age\"] = DP05_tables[i][\"Median Age\"]\n",
        "    DP05_tables[i] = temp\n",
        "\n",
        "    # race\n",
        "    i = 2\n",
        "    # group by master sheet categories\n",
        "    DP05_tables[i].loc[:,\"Other\"] = DP05_tables[i].loc[:,[\"Black\", \"American Indian\", \"Asian\", \"Hawaiian/PI\", \"Other\", \"Two or More\"]].sum(axis = 1)\n",
        "    DP05_tables[i] = DP05_tables[i].drop(columns = [\"Black\", \"American Indian\", \"Asian\", \"Hawaiian/PI\", \"Two or More\"])\n",
        "    DP05_tables[i][\"Total\"] = DP05_tables[i].loc[:,:].sum(axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08912d0f-99df-4f33-b852-9a4e9944c821",
      "metadata": {
        "id": "08912d0f-99df-4f33-b852-9a4e9944c821"
      },
      "source": [
        "## 5.3. DP04"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "921ac5f5-a932-47a9-ad34-452d923323c3",
      "metadata": {
        "id": "921ac5f5-a932-47a9-ad34-452d923323c3"
      },
      "source": [
        "### 5.3.1. Get Data for Housing Stock Master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "5f509a38-010e-4c2a-8ac2-bacf785e0c53",
      "metadata": {
        "id": "5f509a38-010e-4c2a-8ac2-bacf785e0c53"
      },
      "outputs": [],
      "source": [
        "if(include_DP04):\n",
        "    category_names = [\"UTILIZATION\"]\n",
        "    category_target_names = [\n",
        "        [\"Owner Occupied\", \"Renter Occupied\", \"Season/Vac\"]\n",
        "    ]\n",
        "    category_target_codes_dict = get_housing_codes(YEAR)\n",
        "    category_target_codes = [[category_target_codes_dict[label] for label in category_target_names[0]]]\n",
        "\n",
        "    DP04_tables = get_custom_tables(census_tables[ct_index], category_names, category_target_names, category_target_codes)\n",
        "    ct_index += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ae0f142-b73b-4300-8b89-dc1b4465d43d",
      "metadata": {
        "id": "5ae0f142-b73b-4300-8b89-dc1b4465d43d"
      },
      "source": [
        "### 5.3.2. Reformat Data for Master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "1a6c467a-bb60-41b2-929f-c8ca0deeb1e0",
      "metadata": {
        "id": "1a6c467a-bb60-41b2-929f-c8ca0deeb1e0"
      },
      "outputs": [],
      "source": [
        "if(include_DP04):\n",
        "    # add total column\n",
        "    DP04_tables[0].loc[:, \"Total\"] = DP04_tables[0].loc[:,:].sum(axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c47a2449-de69-4a51-bac7-6bf462c40db4",
      "metadata": {
        "id": "c47a2449-de69-4a51-bac7-6bf462c40db4"
      },
      "source": [
        "## 5.4 DP03"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19393a37-c08d-43b6-9427-9b780109ca90",
      "metadata": {
        "id": "19393a37-c08d-43b6-9427-9b780109ca90"
      },
      "source": [
        "### 5.4.1. Get Data for Income Master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "bdbd5e5a-df3a-403e-bcb8-1fb7cd15132d",
      "metadata": {
        "id": "bdbd5e5a-df3a-403e-bcb8-1fb7cd15132d"
      },
      "outputs": [],
      "source": [
        "if(include_DP03):\n",
        "    category_names = [\"INCOME\"]\n",
        "    category_target_names = [\n",
        "        [\"<10k\", \"10k-14k\", \"15k-25k\", \"25k-35k\", \"35k-50k\", \"50k-75k\", \"75k-100k\", \"100k-150k\", \"150k-200k\", \">=200k\", \"Total Households\", \"Median Income\"]\n",
        "    ]\n",
        "    category_target_codes_dict = get_income_codes(YEAR)\n",
        "    category_target_codes = [[category_target_codes_dict[label] for label in category_target_names[0]]]\n",
        "    DP03_tables = get_custom_tables(census_tables[ct_index], category_names, category_target_names, category_target_codes)\n",
        "    ct_index ++ 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aa127d0-b74e-4410-849c-eea867880f95",
      "metadata": {
        "id": "8aa127d0-b74e-4410-849c-eea867880f95"
      },
      "source": [
        "### 5.4.2 Reformat Data for Master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "e20d4ce0-8422-4bf3-8774-9b695f69d42a",
      "metadata": {
        "id": "e20d4ce0-8422-4bf3-8774-9b695f69d42a"
      },
      "outputs": [],
      "source": [
        "if(include_DP03):\n",
        "    df2 = pd.DataFrame()\n",
        "    # aggregate columns\n",
        "    df2.loc[:,\"<25k\"] = DP03_tables[0].loc[:,[\"<10k\", \"10k-14k\", \"15k-25k\"]].sum(axis = 1)\n",
        "    df2.loc[:,\"25k-50k\"] = DP03_tables[0].loc[:,[\"25k-35k\", \"35k-50k\"]].sum(axis = 1)\n",
        "    df2.loc[:, \"50k-75k\"] = DP03_tables[0].loc[:,\"50k-75k\"]\n",
        "    df2.loc[:,\">=75k\"] = DP03_tables[0].loc[:,[\"75k-100k\", \"100k-150k\", \"150k-200k\", \">=200k\"]].sum(axis = 1)\n",
        "    df2.loc[:,\"Total Households\"] = DP03_tables[0].loc[:,\"Total Households\"]\n",
        "    df2.loc[:,\"Median Income\"] = DP03_tables[0].loc[:,\"Median Income\"]\n",
        "    DP03_tables[0] = df2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b69beae3-3bb9-431e-b7fe-257a37e7345e",
      "metadata": {
        "id": "b69beae3-3bb9-431e-b7fe-257a37e7345e"
      },
      "source": [
        "# 6. Exporting to Master Sheet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb831ee7-2bae-4ba0-bdbb-1987a5da34f6",
      "metadata": {
        "id": "cb831ee7-2bae-4ba0-bdbb-1987a5da34f6"
      },
      "source": [
        "## 6.1. Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "b156609d-fb75-4657-b547-79d3ebb463a9",
      "metadata": {
        "id": "b156609d-fb75-4657-b547-79d3ebb463a9"
      },
      "outputs": [],
      "source": [
        "from openpyxl import Workbook\n",
        "from openpyxl import load_workbook\n",
        "from openpyxl.styles import Alignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "e5ae3ee3-6fb8-48c1-adfd-a571e286f9c1",
      "metadata": {
        "id": "e5ae3ee3-6fb8-48c1-adfd-a571e286f9c1"
      },
      "outputs": [],
      "source": [
        "from openpyxl.utils import get_column_letter\n",
        "def grid(col : int, row : int) -> str:\n",
        "    return get_column_letter(col) + str(row)\n",
        "\n",
        "def year_to_int(year : str) -> int:\n",
        "    container = \"\"\n",
        "    for char in year:\n",
        "        if char.isdigit():\n",
        "            container += char\n",
        "    if(len(container) == 0):\n",
        "        return -1\n",
        "    if(len(container) == 2):\n",
        "        if(int(container) > 65):\n",
        "            return int(\"19\" + container)\n",
        "        else:\n",
        "            return int(\"20\" + container)\n",
        "    else:\n",
        "        return int(container)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "dfc68a81-af4e-4042-a641-8375822fe524",
      "metadata": {
        "id": "dfc68a81-af4e-4042-a641-8375822fe524"
      },
      "outputs": [],
      "source": [
        "def insert_into_master(table : pd.DataFrame, table_name : str, col_order : list, source: str, destination : str):\n",
        "    # open sumamry tab of Demographics Master Sheet\n",
        "    wb = load_workbook(filename = source)\n",
        "    wb.active = wb[\"Summary\"]\n",
        "    sheet = wb.active\n",
        "\n",
        "    # find the start of the desired table\n",
        "    curr_row = 1\n",
        "    while(sheet[grid(1, curr_row)].value != table_name):\n",
        "        curr_row += 1\n",
        "    # find the start of the data\n",
        "    curr_row += 2\n",
        "\n",
        "    # find where to insert the new data\n",
        "    while True:\n",
        "        # find where the new data belongs\n",
        "        if((sheet[grid(1, curr_row)].value == \"end_table\") or (year_to_int(sheet[grid(1, curr_row)].value) >= int(YEAR))):\n",
        "            break\n",
        "        curr_row += 1\n",
        "    # if the row doesn't exist, insert it in the right spot\n",
        "    if(year_to_int(sheet[grid(1, curr_row)].value) != int(YEAR)):\n",
        "        sheet.insert_rows(idx = curr_row)\n",
        "\n",
        "    # insert new data\n",
        "    sheet[grid(1, curr_row)].value = \"'\" + YEAR[2:]\n",
        "    sheet[grid(1, curr_row)].alignment = Alignment(horizontal = 'right')\n",
        "    cols_per_location = len(table.columns)\n",
        "    i = 2\n",
        "    while(i < 2 + cols_per_location * len(order)):\n",
        "        location = order[(i - 2)//cols_per_location]\n",
        "        sheet[grid(i, curr_row)].value = table.loc[location].iloc[(i-2)%cols_per_location]\n",
        "        #print(location + \": \" + str(table.loc[location][(i-2)%cols_per_location]))\n",
        "        i += 1\n",
        "    wb.save(destination)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb838ff9-fa4c-43ef-9550-d75f46a97f4f",
      "metadata": {
        "id": "bb838ff9-fa4c-43ef-9550-d75f46a97f4f"
      },
      "source": [
        "## 6.2. Export Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "1e62c286-c48e-48c4-a936-f589f90772c2",
      "metadata": {
        "id": "1e62c286-c48e-48c4-a936-f589f90772c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c01806b-61df-41dd-c108-a5c60aa14f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: SEX_SUMMARY\n",
            "Finished: AGE_SUMMARY\n",
            "Finished: RACE_SUMMARY\n"
          ]
        }
      ],
      "source": [
        "if(include_DP05 == True):\n",
        "    master = \"/content/drive/MyDrive/SVED Economic Profile Auto-Updaters/Masters/MASTER City Demographics 1970-current.xlsx\"\n",
        "    tables = DP05_tables\n",
        "    table_names = [\"SEX_SUMMARY\", \"AGE_SUMMARY\", \"RACE_SUMMARY\"]\n",
        "    order = [\"CAREY\", \"BELLEVUE\", \"HAILEY\", \"KETCHUM\", \"SV\", \"BLAINE\"]\n",
        "    for i in range(0,len(table_names)):\n",
        "        insert_into_master(tables[i], table_names[i], order, master, master)\n",
        "        print(\"Finished: \" + table_names[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "afc48a0e-c231-41ed-9bfd-f5a2523e344f",
      "metadata": {
        "id": "afc48a0e-c231-41ed-9bfd-f5a2523e344f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153d99b5-e678-42e7-f946-35861f7a39b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: HOUSING_STOCK_SUMMARY\n"
          ]
        }
      ],
      "source": [
        "if(include_DP04 == True):\n",
        "    master = '/content/drive/MyDrive/SVED Economic Profile Auto-Updaters/Masters/MASTER City Housing Stock 2011-current.xlsx'\n",
        "    tables = DP04_tables\n",
        "    table_names = [\"HOUSING_STOCK_SUMMARY\"]\n",
        "    order = [\"CAREY\", \"BELLEVUE\", \"HAILEY\", \"KETCHUM\", \"SV\", \"BLAINE\"]\n",
        "    for i in range(0, len(tables)):\n",
        "        insert_into_master(tables[i], table_names[i], order, master, master)\n",
        "        print(\"Finished: \" + table_names[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "905bc311-d10c-41a7-87f8-d7d864135277",
      "metadata": {
        "id": "905bc311-d10c-41a7-87f8-d7d864135277",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100e5fd9-526f-49e9-c33c-d04773f78ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: INCOME_SUMMARY\n"
          ]
        }
      ],
      "source": [
        "if(include_DP03 == True):\n",
        "    master = '/content/drive/MyDrive/SVED Economic Profile Auto-Updaters/Masters/MASTER City Income Distribution 2011-current.xlsx'\n",
        "    tables = DP03_tables\n",
        "    table_names = [\"INCOME_SUMMARY\"]\n",
        "    order = [\"CAREY\", \"BELLEVUE\", \"HAILEY\", \"KETCHUM\", \"SV\", \"BLAINE\"]\n",
        "    for i in range(0, len(tables)):\n",
        "        insert_into_master(tables[i], table_names[i], order, master, master)\n",
        "        print(\"Finished: \" + table_names[i])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}